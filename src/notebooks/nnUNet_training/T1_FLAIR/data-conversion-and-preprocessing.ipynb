{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13340862,"sourceType":"datasetVersion","datasetId":8459864},{"sourceId":13426905,"sourceType":"datasetVersion","datasetId":8522190}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport shutil\nimport json\nimport glob\n\n\n!pip install nnunetv2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:30:10.572889Z","iopub.execute_input":"2025-10-19T12:30:10.573205Z","iopub.status.idle":"2025-10-19T12:31:59.582492Z","shell.execute_reply.started":"2025-10-19T12:30:10.573177Z","shell.execute_reply":"2025-10-19T12:31:59.581276Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Environment Setup and Directory Creation","metadata":{}},{"cell_type":"code","source":"os.environ['nnUNet_raw_data_base'] = '/kaggle/working/nnUNet_raw_data_base'\nos.environ['nnUNet_preprocessed'] = '/kaggle/working/nnUNet_preprocessed'\n\n# 3. Create necessary directories\n!mkdir -p $nnUNet_raw_data_base/nnUNet_raw/Dataset001_FCDLesions\n!mkdir -p $nnUNet_preprocessed\n\nprint(\"nnUNet environment setup complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:31:59.584522Z","iopub.execute_input":"2025-10-19T12:31:59.585176Z","iopub.status.idle":"2025-10-19T12:31:59.828421Z","shell.execute_reply.started":"2025-10-19T12:31:59.585132Z","shell.execute_reply":"2025-10-19T12:31:59.827302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nUPLOADED_DATASET_NAME = 'participants' \nCSV_DATASET_ROOT = f'/kaggle/input/{UPLOADED_DATASET_NAME}'\n\nprint(f\"Listing files in the root of your uploaded metadata dataset ({CSV_DATASET_ROOT}):\")\nif os.path.exists(CSV_DATASET_ROOT):\n    # This will print the actual file name (e.g., ['participants.csv'] or ['participants.xlsx'])\n    print(os.listdir(CSV_DATASET_ROOT))\nelse:\n    print(f\"Error: The dataset root {CSV_DATASET_ROOT} was not found. Please verify the uploaded dataset name.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:31:59.829996Z","iopub.execute_input":"2025-10-19T12:31:59.830404Z","iopub.status.idle":"2025-10-19T12:32:00.222721Z","shell.execute_reply.started":"2025-10-19T12:31:59.830363Z","shell.execute_reply":"2025-10-19T12:32:00.221732Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Conversion and dataset.json Generation","metadata":{}},{"cell_type":"code","source":"\n# --- ðŸŽ¯ FINAL PATHS AND NAMES ðŸŽ¯ ---\nBASE_DIR = '/kaggle/input/organized-bonn-fcd-ii-epilepsy-mri-dataset/bonn_fcd_fixed' \nUPLOADED_DATASET_NAME = 'participants' \nEXCEL_FILE_NAME = 'participants.xlsx' \nEXCEL_PATH = os.path.join('/kaggle/input', UPLOADED_DATASET_NAME, EXCEL_FILE_NAME)\n# ---------------------------------------------\n\nTASK_ID = 1\nTASK_NAME = 'Dataset001_FCDLesions' \nNNUNET_RAW_DATA_DIR = os.path.join(os.environ['nnUNet_raw_data_base'], 'nnUNet_raw', TASK_NAME) \n\n# Create target directories\nIMAGES_TR_DIR = os.path.join(NNUNET_RAW_DATA_DIR, 'imagesTr')\nLABELS_TR_DIR = os.path.join(NNUNET_RAW_DATA_DIR, 'labelsTr')\nIMAGES_TS_DIR = os.path.join(NNUNET_RAW_DATA_DIR, 'imagesTs')\n\nos.makedirs(IMAGES_TR_DIR, exist_ok=True)\nos.makedirs(LABELS_TR_DIR, exist_ok=True)\nos.makedirs(IMAGES_TS_DIR, exist_ok=True)\n\n# --- 1. Load and Filter the Excel Data ---\nprint(f\"Attempting to read Excel file from: {EXCEL_PATH}\")\n\ntry:\n    participants_df = pd.read_excel(EXCEL_PATH, sheet_name='participants')\nexcept ValueError:\n    xls = pd.ExcelFile(EXCEL_PATH)\n    print(f\"Available sheets: {xls.sheet_names}\")\n    participants_df = pd.read_excel(xls, sheet_name=xls.sheet_names[0])\nexcept Exception as e:\n    print(f\"FATAL ERROR: Could not read Excel file. Please verify the EXCEL_PATH: {EXCEL_PATH}. Error: {e}\")\n    raise\n\n# Ensure required columns exist\nrequired_columns = {'participant_id', 'group', 'split'}\nmissing_columns = required_columns - set(participants_df.columns)\nif missing_columns:\n    raise Exception(f\"Missing required columns in Excel file: {missing_columns}\")\n\n# Filter FCD subjects for training and testing\ntrain_fcd_subjects = participants_df[\n    (participants_df['group'].str.lower() == 'fcd') & \n    (participants_df['split'].str.lower() == 'train')\n]['participant_id'].tolist()\n\ntest_fcd_subjects = participants_df[\n    (participants_df['group'].str.lower() == 'fcd') & \n    (participants_df['split'].str.lower() == 'test')\n]['participant_id'].tolist()\n\nprint(f\"Total FCD subjects for TRAINING: {len(train_fcd_subjects)}\")\nprint(f\"Total FCD subjects for TESTING: {len(test_fcd_subjects)}\")\n\ntraining_files = []\ntest_files = []\nskipped_subjects = []\n\n# --- Helper Function to Process Subjects ---\ndef process_subject(subject_id, target_images_dir, is_training=True):\n    subject_path_with_anat = os.path.join(BASE_DIR, subject_id, 'anat')\n    \n    if not os.path.exists(subject_path_with_anat):\n        return False, f\"'anat' folder missing\"\n\n    # Look for relevant MRI and label files\n    t1w_search_pattern = os.path.join(subject_path_with_anat, f'{subject_id}*_T1w.nii')\n    flair_search_pattern = os.path.join(subject_path_with_anat, f'{subject_id}*_FLAIR.nii')\n    label_search_pattern = os.path.join(subject_path_with_anat, f'{subject_id}*_FLAIR_roi.nii')\n    \n    t1w_files = glob.glob(t1w_search_pattern)\n    flair_files = glob.glob(flair_search_pattern)\n    label_files = glob.glob(label_search_pattern)\n    \n    # Validation checks\n    if len(t1w_files) != 1 or len(flair_files) != 1:\n        return False, f\"Image ambiguity: Found {len(t1w_files)} T1w, {len(flair_files)} FLAIR.\"\n\n    if is_training and len(label_files) != 1:\n        return False, f\"Training subject missing label file (found {len(label_files)}).\"\n\n    # Prepare target filenames\n    t1w_target_name = f'{subject_id}_0000.nii'\n    flair_target_name = f'{subject_id}_0001.nii'\n    label_target_name = f'{subject_id}.nii'\n    \n    try:\n        # Copy MRI modalities\n        shutil.copy(t1w_files[0], os.path.join(target_images_dir, t1w_target_name))\n        shutil.copy(flair_files[0], os.path.join(target_images_dir, flair_target_name))\n        \n        if is_training:\n            shutil.copy(label_files[0], os.path.join(LABELS_TR_DIR, label_target_name))\n            return True, {\"image\": f\"./imagesTr/{subject_id}\", \"label\": f\"./labelsTr/{subject_id}.nii\"}\n        else:\n            return True, {\"image\": f\"./imagesTs/{subject_id}\"}\n            \n    except Exception as e:\n        return False, f\"Copy error: {e}\"\n\n# --- 2. Process Training and Test Subjects ---\nprint(\"\\n--- Processing Training Subjects ---\")\nfor subject_id in train_fcd_subjects:\n    success, result = process_subject(subject_id, IMAGES_TR_DIR, is_training=True)\n    if success:\n        training_files.append(result)\n    else:\n        skipped_subjects.append((subject_id, f\"TRAIN - {result}\"))\n\nprint(\"\\n--- Processing Test Subjects ---\")\nfor subject_id in test_fcd_subjects:\n    success, result = process_subject(subject_id, IMAGES_TS_DIR, is_training=False)\n    if success:\n        test_files.append(result)\n    else:\n        skipped_subjects.append((subject_id, f\"TEST - {result}\"))\n\n# --- 3. Generate dataset.json ---\ndataset_json = {\n    \"name\": \"FCD Lesion Segmentation\",\n    \"description\": \"Focal Cortical Dysplasia Lesion Segmentation Dataset (Pre-defined Splits)\",\n    \"reference\": \"your/publication/link/here\",\n    \"licence\": \"CC-BY-4.0\",\n    \"release\": \"1.0\",\n    \"channel_names\": {\n        \"0\": \"T1w\",\n        \"1\": \"FLAIR\"\n    },\n    \"labels\": {\n        \"background\": 0,\n        \"lesion\": 1\n    },\n    \"numTraining\": len(training_files),\n    \"file_ending\": \".nii\",\n    \"training\": training_files,\n    \"test\": test_files\n}\n\n# Save JSON\nwith open(os.path.join(NNUNET_RAW_DATA_DIR, 'dataset.json'), 'w') as f:\n    json.dump(dataset_json, f, indent=4)\n\nprint(f\"\\nâœ… Conversion complete!\")\nprint(f\"  Training subjects: {len(training_files)}\")\nprint(f\"  Test subjects: {len(test_files)}\")\n\nif skipped_subjects:\n    print(\"\\n--- âš ï¸ Skipped Subjects Summary ---\")\n    for subj, reason in skipped_subjects:\n        print(f\"  {subj}: {reason}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:32:00.224034Z","iopub.execute_input":"2025-10-19T12:32:00.224407Z","iopub.status.idle":"2025-10-19T12:32:48.061495Z","shell.execute_reply.started":"2025-10-19T12:32:00.224362Z","shell.execute_reply":"2025-10-19T12:32:48.060464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Registration","metadata":{}},{"cell_type":"code","source":"!pip install SimpleITK -q\n\nimport SimpleITK as sitk\nfrom tqdm import tqdm\n\n# Paths\nDATASET_PATH = '/kaggle/working/nnUNet_raw_data_base/nnUNet_raw/Dataset001_FCDLesions'\nIMAGES_TR = os.path.join(DATASET_PATH, 'imagesTr')\nLABELS_TR = os.path.join(DATASET_PATH, 'labelsTr')\nIMAGES_TS = os.path.join(DATASET_PATH, 'imagesTs')\n\ndef register_flair_to_t1(subject_id, folder, is_training=True, transform_type='rigid'):\n    \"\"\"\n    Register FLAIR to T1 for a given subject and apply same transform to label.\n    \"\"\"\n    t1_path = os.path.join(folder, f\"{subject_id}_0000.nii\")\n    flair_path = os.path.join(folder, f\"{subject_id}_0001.nii\")\n\n    if not (os.path.exists(t1_path) and os.path.exists(flair_path)):\n        print(f\"âš ï¸ Missing T1 or FLAIR for {subject_id}\")\n        return False\n\n    # Load images\n    t1 = sitk.ReadImage(t1_path, sitk.sitkFloat32)\n    flair = sitk.ReadImage(flair_path, sitk.sitkFloat32)\n\n    # Initialize registration\n    registration_method = sitk.ImageRegistrationMethod()\n    registration_method.SetMetricAsMattesMutualInformation(numberOfHistogramBins=50)\n    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n    registration_method.SetMetricSamplingPercentage(0.2)\n    registration_method.SetInterpolator(sitk.sitkLinear)\n    registration_method.SetOptimizerAsGradientDescent(learningRate=1.0, numberOfIterations=100)\n    registration_method.SetOptimizerScalesFromPhysicalShift()\n\n    # Select transform type\n    if transform_type == 'rigid':\n        transform = sitk.CenteredTransformInitializer(t1, flair, sitk.Euler3DTransform())\n    else:\n        transform = sitk.CenteredTransformInitializer(t1, flair, sitk.AffineTransform(3))\n\n    registration_method.SetInitialTransform(transform, inPlace=False)\n    registration_method.SetShrinkFactorsPerLevel(shrinkFactors=[4,2,1])\n    registration_method.SetSmoothingSigmasPerLevel(smoothingSigmas=[2,1,0])\n    registration_method.SmoothingSigmasAreSpecifiedInPhysicalUnitsOn()\n\n    # Perform registration\n    final_transform = registration_method.Execute(t1, flair)\n\n    # Resample FLAIR to T1 space\n    resampled_flair = sitk.Resample(flair, t1, final_transform,\n                                    sitk.sitkLinear, 0.0, flair.GetPixelID())\n    sitk.WriteImage(resampled_flair, flair_path)\n\n    # Resample label if training\n    if is_training:\n        label_path = os.path.join(LABELS_TR, f\"{subject_id}.nii\")\n        if os.path.exists(label_path):\n            label_img = sitk.ReadImage(label_path, sitk.sitkUInt8)\n            resampled_label = sitk.Resample(label_img, t1, final_transform,\n                                            sitk.sitkNearestNeighbor, 0.0, label_img.GetPixelID())\n            sitk.WriteImage(resampled_label, label_path)\n        else:\n            print(f\"âš ï¸ Label missing for {subject_id}\")\n\n    return True\n\n\n# --- Apply to all subjects ---\nprint(\" Starting registration for training set...\")\ntrain_subjects = sorted(set([f.split('_')[0] for f in os.listdir(IMAGES_TR) if f.endswith('_0000.nii')]))\n\nfor subj in tqdm(train_subjects):\n    register_flair_to_t1(subj, IMAGES_TR, is_training=True, transform_type='rigid')\n\nprint(\" Starting registration for test set...\")\ntest_subjects = sorted(set([f.split('_')[0] for f in os.listdir(IMAGES_TS) if f.endswith('_0000.nii')]))\n\nfor subj in tqdm(test_subjects):\n    register_flair_to_t1(subj, IMAGES_TS, is_training=False, transform_type='rigid')\n\nprint(\" Registration complete for all subjects!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:32:48.063690Z","iopub.execute_input":"2025-10-19T12:32:48.064188Z","iopub.status.idle":"2025-10-19T13:06:20.237260Z","shell.execute_reply.started":"2025-10-19T12:32:48.064132Z","shell.execute_reply":"2025-10-19T13:06:20.235523Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Planning and Preprocessing","metadata":{}},{"cell_type":"code","source":"import os\n\n# Fix environment variables for nnUNetv2\nos.environ['nnUNet_raw'] = '/kaggle/working/nnUNet_raw_data_base/nnUNet_raw'\nos.environ['nnUNet_preprocessed'] = '/kaggle/working/nnUNet_preprocessed'\nos.environ['nnUNet_results'] = '/kaggle/working/nnUNet_results'\n\n# Confirm theyâ€™re visible\nfor k in ['nnUNet_raw', 'nnUNet_preprocessed', 'nnUNet_results']:\n    print(f\"{k} -> {os.environ[k]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:26:07.021234Z","iopub.execute_input":"2025-10-19T13:26:07.021868Z","iopub.status.idle":"2025-10-19T13:26:07.031229Z","shell.execute_reply.started":"2025-10-19T13:26:07.021836Z","shell.execute_reply":"2025-10-19T13:26:07.029939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nnUNetv2_plan_and_preprocess -d 1 --verify_dataset_integrity","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T13:26:10.974521Z","iopub.execute_input":"2025-10-19T13:26:10.974940Z","iopub.status.idle":"2025-10-19T13:45:22.460793Z","shell.execute_reply.started":"2025-10-19T13:26:10.974912Z","shell.execute_reply":"2025-10-19T13:45:22.459390Z"}},"outputs":[],"execution_count":null}]}